{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclass Submission: Use the code below and try to build multipe ANN models using combinations of hyper parameters, Optimisers and Activation function/Layers\n",
    "\n",
    "Please use seed value of 42 to be consistent with the lead instructor. Model 1 and Model 2 has been done for you. Feel free to choose your own combination  - 5 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read in the insurance dataset\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the data\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all categories into numbers\n",
    "insurance_one_hot = pd.get_dummies(insurance)\n",
    "insurance_one_hot.head() # view the converted columns\n",
    "# Create X & y values\n",
    "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
    "y = insurance_one_hot[\"charges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) # set random state for reproducible splits\n",
    "\n",
    "# Create column transformer (this will help us normalize/preprocess our data)\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # get all values between 0 and 1\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create X & y\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "\n",
    "# Build our train and test sets (use random state to ensure same split as before)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-normalized and non-one-hot encoded data example\n",
    "X_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized and one-hot encoded example\n",
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 11), (1070, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the normalized/one-hot encoded shape is larger because of the extra columns\n",
    "X_train_normal.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link for Optimisers https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 --> Use SGD with no momemtum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2611787bf70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Build the model (3 layers, 100, 10,1 units)\n",
    "insurance_model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_1.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model for 200 epochs (call it model 1)\n",
    "insurance_model_1.fit(X_train_normal, y_train, epochs=200, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3486.6892 - mae: 3486.6892\n"
     ]
    }
   ],
   "source": [
    "insurance_model_1_loss, insurance_model_1_mae = insurance_model_1.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,221\n",
      "Trainable params: 2,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the model summary\n",
    "insurance_model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 --> Use Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261168865b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Build the model (3 layers, 100, 10, 1 units)\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    " \n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model for 200 epochs (same as insurance_model_1)\n",
    "insurance_model_2.fit(X_train_normal, y_train, epochs=200, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 769us/step - loss: 3171.5774 - mae: 3171.5774\n"
     ]
    }
   ],
   "source": [
    "# Evaulate 2nd model\n",
    "insurance_model_2_loss, insurance_model_2_mae = insurance_model_2.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 --> Add another hidden layer with 100 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26122026250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model for 200 epochs (same as insurance_model_1)\n",
    "insurance_model_3.fit(X_train_normal, y_train, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 3175.5801 - mae: 3175.5801\n"
     ]
    }
   ],
   "source": [
    "# Evaulate 3rd model\n",
    "insurance_model_3_loss, insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 --> SGD with momemtum=0.9  + Back to 3 layers + Change learning rate= 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2612213ff10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_4.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum =0.9), metrics=['mae'])\n",
    "\n",
    "# Fit the model for 200 epochs (same as insurance_model_1)\n",
    "insurance_model_4.fit(X_train_normal, y_train, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 638us/step - loss: 3821.8406 - mae: 3821.8406\n"
     ]
    }
   ],
   "source": [
    "# Evaulate 4rd model\n",
    "insurance_model_4_loss, insurance_model_4_mae = insurance_model_4.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5 --> RMS Prop with momemtum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26123316310>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    #name='RMSprop'\n",
    "\n",
    "    # Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "insurance_model_5 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_5.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, momentum =0.9), metrics=['mae'])\n",
    "\n",
    "# Fit the model for 200 epochs (same as insurance_model_1)\n",
    "insurance_model_5.fit(X_train_normal, y_train, epochs=200, verbose=0)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3160.7859 - mae: 3160.7859\n"
     ]
    }
   ],
   "source": [
    "# Evaulate 5rd model\n",
    "insurance_model_5_loss, insurance_model_5_mae = insurance_model_5.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6 --> Adagrad + more epocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261233d8580>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "insurance_model_6 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_6.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.001), metrics=['mae'])\n",
    "\n",
    "# Fit the model for 200 epochs (same as insurance_model_1)\n",
    "insurance_model_6.fit(X_train_normal, y_train, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 12791.0166 - mae: 12791.0166\n"
     ]
    }
   ],
   "source": [
    "# Evaulate 6th model\n",
    "insurance_model_6_loss, insurance_model_6_mae = insurance_model_6.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 7 --> Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26123490340>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    # Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "insurance_model_7 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_7.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001), metrics=['mae'])\n",
    "\n",
    "# Fit the model for 200 epochs (same as insurance_model_1)\n",
    "insurance_model_7.fit(X_train_normal, y_train, epochs=200, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 3169.7285 - mae: 3169.7285\n"
     ]
    }
   ],
   "source": [
    "# Evaulate 7th model\n",
    "insurance_model_7_loss, insurance_model_7_mae = insurance_model_7.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
